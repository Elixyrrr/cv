<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BERT on Ilyes Khedhiri</title>
    <link>http://localhost:1313/tags/bert/</link>
    <description>Recent content in BERT on Ilyes Khedhiri</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 May 2025 12:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/bert/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Détection de signes dépressifs dans les publications sur les réseaux sociaux</title>
      <link>http://localhost:1313/projects/creations/docker-marketplace/</link>
      <pubDate>Thu, 15 May 2025 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/creations/docker-marketplace/</guid>
      <description>&lt;ul&gt;&#xA;&lt;li&gt;Corpus : 30 000 posts annotés (15 000 dépressifs / 15 000 non-dépressifs) et 6 000 tweets équilibrés pour évaluer la généralisation.&lt;/li&gt;&#xA;&lt;li&gt;Méthodes testées :&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;TF-IDF + SVM / Random Forest&lt;/strong&gt; → jusqu’à 90,20 % d’accuracy sur le grand jeu de 30 K.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;FastText + CNN-LSTM&lt;/strong&gt; → embeddings auto-entraînés, atteignant 90,22 % d’accuracy (30 K) et 82,42 % (6 K).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;BERT + LSTM (fine-tuné)&lt;/strong&gt; → embeddings contextuels, accuracy finale 91,02 % sur 30 K.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Conclusion : le modèle BERT+LSTM obtient la meilleure F1 (≈ 0,91) et réduit les faux positifs liés au langage informel des réseaux sociaux (slang, emojis, hashtags).&lt;/li&gt;&#xA;&lt;li&gt;Déploiement : prototype Streamlit pour détection en temps réel, destinataire d’une alerte automatique si un post est classé à risque.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
