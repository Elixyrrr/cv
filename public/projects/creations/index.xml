<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projets on Ilyes Khedhiri</title>
    <link>http://localhost:1313/projects/creations/</link>
    <description>Recent content in Projets on Ilyes Khedhiri</description>
    <generator>Hugo</generator>
    <language>fr</language>
    <lastBuildDate>Sat, 31 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/projects/creations/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Évaluation de la qualité d’un graphe de connaissance avec un pipeline RAG</title>
      <link>http://localhost:1313/projects/creations/kg/</link>
      <pubDate>Sat, 31 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/creations/kg/</guid>
      <description>&lt;p&gt;RAG (Retrieval-Augmented Generation) « &lt;!-- raw HTML omitted --&gt;est une méthode qui enrichit les prompts du LLM avec un contexte pertinent récupéré pour réduire les hallucinations et améliorer la précision factuelle.&lt;!-- raw HTML omitted --&gt; »  .Dans ce projet on utilise Ollama pour exécuter un LLM local qui, à partir de triplets récupérés par FAISS depuis un graphe de connaissance, va évaluer la qualité du graphe en comparant les réponses générées aux données sources.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Application Big Data</title>
      <link>http://localhost:1313/projects/creations/bayesian/</link>
      <pubDate>Thu, 15 May 2025 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/creations/bayesian/</guid>
      <description>&lt;p&gt;Les bases de données traditionnelles Oracle, SQL Server DB2 ont été conçues pour garantir l&amp;rsquo;accès concurrent aux données, l&amp;rsquo;aspect transactionnel des traitements, pour pouvoir accepter des centaines de sessions utilisateurs, pour fournir des métriques précises sur l&amp;rsquo;utilisation du système au niveau de processeur, mémoire, réseau.&lt;/p&gt;&#xA;&lt;p&gt;Ces bases de données sont donc plus lentes en terme de consultation de données massives et non structurées.&lt;/p&gt;&#xA;&lt;p&gt;Des nouvelles technologies comme Hadoop sont orientées plus vers la consultation des données, traitement massif des données, structurées ou non structurés.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Détection de signes dépressifs dans les publications sur les réseaux sociaux</title>
      <link>http://localhost:1313/projects/creations/depression/</link>
      <pubDate>Thu, 15 May 2025 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/creations/depression/</guid>
      <description>&lt;p&gt;Ce projet consistait à développer un outil capable d’analyser des contenus publiés sur les réseaux sociaux pour détecter des messages témoignant de signes dépressifs, en utilisant des techniques de deep learning tels que &amp;ldquo;FCL&amp;rdquo; ou bien de machine learning tels que &amp;ldquo;SVM&amp;rdquo; et &amp;ldquo;Random Forest&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jeu d’échecs en ligne</title>
      <link>http://localhost:1313/projects/creations/chess/</link>
      <pubDate>Thu, 15 May 2025 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/creations/chess/</guid>
      <description>&lt;p&gt;Le projet consistait à créer une application web de jeu d’échecs conforme à une architecture REST (Répresentationnal State Transfer) et au pattern MVC (Modèle-Vue-Contrôleur). Les deux joueurs peuvent s’affronter en temps réel via Socket.IO, et chaque partie est sauvegardée dans MongoDB (ou SQL) pour être reprise coup par coup. Des fonctionnalités annexes, comme le chronomètre, la demande de partie à l’adversaire et la possibilité de rejouer un coup, ont été implémentées. En bonus, une IA basique a été développée pour permettre à l’utilisateur de jouer contre l’ordinateur. Les technologies employées incluent Node.js, Express, Socket.IO et MongoDB.&#xA;Le site prend un peu de temps à se lancer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Imputation des valeurs manquantes dans les séries temporelles d’électricité</title>
      <link>http://localhost:1313/projects/creations/imputation/</link>
      <pubDate>Tue, 15 Apr 2025 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/creations/imputation/</guid>
      <description>&lt;p&gt;Ce projet consiste à combler les valeurs manquantes dans des séries temporelles de consommation électrique résidentielle, mesurées toutes les 30 minutes. Nous disposons de 3 127 séries d’entraînement de 12 864 relevés chacune, sans valeurs manquantes, puis de jeux de test comportant environ 30 % de mesures masquées aléatoirement. Pour restaurer ces données, nous avons implémenté et comparé plusieurs approches : méthodes statistiques classiques (interpolations, moyennes mobiles), algorithmes de machine learning (régressions, forêts aléatoires) et modèles de deep learning (LSTM, CNN, autoencodeurs). Chaque méthode est évaluée à l’aide de l’erreur moyenne absolue (MAE) entre les valeurs prédictes et réelles, afin de déterminer la solution la plus efficace pour reconstituer fidèlement les courbes de consommation.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
